{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LadderNet(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super(LadderNet, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Encoder layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.deconv4 = nn.ConvTranspose2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(32)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 1, kernel_size=4, padding=1)\n",
    "\n",
    "        # Classification layer\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x_labeled, x_unlabeled):\n",
    "        # Labeled input\n",
    "        h = F.relu(self.bn1(self.conv1(x_labeled)))\n",
    "        h = F.max_pool2d(h, 2, 2)\n",
    "        h = F.relu(self.bn2(self.conv2(h)))\n",
    "        h = F.max_pool2d(h, 2, 2)\n",
    "        h = F.relu(self.bn3(self.conv3(h)))\n",
    "        h = F.max_pool2d(h, 2, 2)\n",
    "        h = F.relu(self.bn4(self.conv4(h)))\n",
    "        h_labeled = F.avg_pool2d(h, h.size()[2:])\n",
    "        h_labeled = h_labeled.view(-1, 256)\n",
    "\n",
    "        # Unlabeled input\n",
    "        u = F.relu(self.bn1(self.conv1(x_unlabeled)))\n",
    "        u = F.max_pool2d(u, 2, 2)\n",
    "        u = F.relu(self.bn2(self.conv2(u)))\n",
    "        u = F.max_pool2d(u, 2, 2)\n",
    "        u = F.relu(self.bn3(self.conv3(u)))\n",
    "        u = F.max_pool2d(u, 2, 2)\n",
    "        u = F.relu(self.bn4(self.conv4(u)))\n",
    "        h_unlabeled = F.avg_pool2d(u, u.size()[2:])\n",
    "        h_unlabeled = h_unlabeled.view(-1, 256)\n",
    "        # Add noise to the hidden representations\n",
    "        noise_labeled = torch.randn_like(h_labeled)\n",
    "        noise_unlabeled = torch.randn_like(h_unlabeled)\n",
    "        h_labeled_noisy = h_labeled + noise_labeled\n",
    "        h_unlabeled_noisy = h_unlabeled + noise_unlabeled\n",
    "\n",
    "        # Decoder\n",
    "        u = F.relu(self.bn5(self.deconv4(h_labeled_noisy.view(-1, 256, 1, 1))))\n",
    "        u = F.interpolate(u, scale_factor=3, mode='nearest')\n",
    "        u = F.relu(self.bn6(self.deconv3(u)))\n",
    "        u = F.interpolate(u, scale_factor=3, mode='nearest')\n",
    "        u = F.relu(self.bn7(self.deconv2(u)))\n",
    "        u = F.interpolate(u, scale_factor=3, mode='nearest')\n",
    "        x_reconstructed = torch.sigmoid(self.deconv1(u))\n",
    "\n",
    "        # Classification\n",
    "        output = self.fc(h_labeled)\n",
    "\n",
    "        return output, x_reconstructed, h_labeled, h_unlabeled_noisy\n",
    "\n",
    "    def labeled_loss(self, output_labeled, target_labeled):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion(output_labeled, target_labeled)\n",
    "\n",
    "    def unlabeled_loss(self, x_reconstructed, x_unlabeled, h_labeled, h_unlabeled_noisy):\n",
    "        # MSE loss between reconstructed and unlabeled input\n",
    "        mse_loss = nn.MSELoss()\n",
    "        mse = mse_loss(x_reconstructed, x_unlabeled)\n",
    "        # KL divergence between hidden representations with noise and without noise\n",
    "        kl_div = 0.5 * torch.mean(\n",
    "            torch.sum(h_unlabeled_noisy.pow(2), dim=1) - torch.sum(h_unlabeled_noisy - h_labeled.pow(2),\n",
    "                                                                   dim=1) + torch.sum(\n",
    "                torch.log(torch.std(h_labeled, dim=0) / torch.std(h_unlabeled_noisy, dim=0))))\n",
    "\n",
    "        return mse + kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_set = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Divide the training set into labeled and unlabeled sets\n",
    "n_labeled = int(0.1 * len(train_set))\n",
    "n_unlabeled = len(train_set) - n_labeled\n",
    "train_labeled_set, train_unlabeled_set = torch.utils.data.random_split(train_set, [n_labeled, n_unlabeled])\n",
    "\n",
    "# Create data loaders for the labeled and unlabeled sets\n",
    "batch_size = 128"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SemisupervisedDataset(Dataset):\n",
    "    def __init__(self, labeled_dataset, unlabeled_dataset):\n",
    "        self.labeled_dataset = labeled_dataset\n",
    "        self.unlabeled_dataset = unlabeled_dataset\n",
    "        self.unlabeled_size = len(unlabeled_dataset)\n",
    "        self.labeled_size = len(labeled_dataset)\n",
    "        print(\"Dataset created\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labeled_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        labeled_data, labeled_target = self.labeled_dataset[index % self.labeled_size]\n",
    "        unlabeled_data, _ = self.unlabeled_dataset[index]\n",
    "\n",
    "        return labeled_data, labeled_target, unlabeled_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n"
     ]
    }
   ],
   "source": [
    "dataset = SemisupervisedDataset(train_labeled_set, train_unlabeled_set)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Define the model\n",
    "model = LadderNet(input_shape=(1, 28, 28), num_classes=10)\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss functions\n",
    "labeled_loss_fn = model.labeled_loss\n",
    "unlabeled_loss_fn = model.unlabeled_loss\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:08<01:14,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Test set: Average loss: 0.0051, Accuracy: 7732/10000 (77%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:14<00:55,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Test set: Average loss: 0.0041, Accuracy: 8113/10000 (81%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:20<00:45,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Test set: Average loss: 0.0038, Accuracy: 8280/10000 (83%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:26<00:37,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Test set: Average loss: 0.0032, Accuracy: 8577/10000 (86%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:32<00:30,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Test set: Average loss: 0.0030, Accuracy: 8656/10000 (87%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:37<00:24,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Test set: Average loss: 0.0045, Accuracy: 8221/10000 (82%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:43<00:18,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Test set: Average loss: 0.0034, Accuracy: 8589/10000 (86%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:49<00:12,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Test set: Average loss: 0.0039, Accuracy: 8512/10000 (85%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:55<00:05,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Test set: Average loss: 0.0056, Accuracy: 8003/10000 (80%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:01<00:00,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Test set: Average loss: 0.0047, Accuracy: 8292/10000 (83%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Train the model\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for data_labeled, target_labeled, data_unlabeled in dataloader:\n",
    "        # Train the model on the labeled data\n",
    "        data_labeled = data_labeled.to(device)\n",
    "        target_labeled = target_labeled.to(device)\n",
    "        data_unlabeled = data_unlabeled.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_labeled, x_reconstructed, h_labeled, h_unlabeled_noisy = model(data_labeled, data_unlabeled)\n",
    "        loss_labeled = labeled_loss_fn(output_labeled, target_labeled)\n",
    "        loss_labeled.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Train the model on the unlabeled data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x_unlabeled = data_unlabeled.view(-1, 784)\n",
    "        x_reconstructed = x_reconstructed.view(-1, 784)\n",
    "        loss_unlabeled = unlabeled_loss_fn(x_reconstructed, x_unlabeled, h_labeled, h_unlabeled_noisy)\n",
    "        # loss_unlabeled.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output, _, _, _ = model(data, data_unlabeled)\n",
    "            test_loss += labeled_loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('Epoch: {} Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(epoch, test_loss, correct, len(test_loader.dataset), accuracy))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
